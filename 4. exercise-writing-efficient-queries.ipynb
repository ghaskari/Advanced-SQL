{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [Advanced SQL](https://www.kaggle.com/learn/advanced-sql) course.  You can reference the tutorial at [this link](https://www.kaggle.com/alexisbcook/writing-efficient-queries).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"# Introduction\n\nNow, you'll use what you learned in the previous tutorial to improve the efficiency of several queries.\n\nBefore you get started, run the following cell to set everything up.","metadata":{}},{"cell_type":"code","source":"# Set up feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.sql_advanced.ex4 import *\nprint(\"Setup Complete\")","metadata":{"execution":{"iopub.status.busy":"2022-10-01T14:26:33.260755Z","iopub.execute_input":"2022-10-01T14:26:33.261292Z","iopub.status.idle":"2022-10-01T14:26:33.340605Z","shell.execute_reply.started":"2022-10-01T14:26:33.261200Z","shell.execute_reply":"2022-10-01T14:26:33.338519Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Setup Complete\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Exercises\n\n### 1) You work for Pet Costumes International.\n\nYou need to write three queries this afternoon. You have enough time to write working versions of all three, but only enough time to think about optimizing one of them.  Which of these queries is most worth optimizing?\n\n1. A software engineer wrote an app for the shipping department, to see what items need to be shipped and which aisle of the warehouse to go to for those items. She wants you to write the query. It will involve data that is stored in an `orders` table, a `shipments` table and a `warehouseLocation` table. The employees in the shipping department will pull up this app on a tablet, hit refresh, and your query results will be shown in a nice interface so they can see what costumes to send where.\n\n\n2. The CEO wants a list of all customer reviews and complaints… which are conveniently stored in a single `reviews` table. Some of the reviews are really long… because people love your pirate costumes for parrots, and they can’t stop writing about how cute they are.\n\n\n3. Dog owners are getting more protective than ever. So your engineering department has made costumes with embedded GPS trackers and wireless communication devices. They send the costumes’ coordinates to your database once a second. You then have a website where owners can find the location of their dogs (or at least the costumes they have for those dogs). For this service to work, you need a query that shows the most recent location for all costumes owned by a given human. This will involve data in a `CostumeLocations` table as well as a `CostumeOwners` table.\n\nSo, which of these could benefit most from being written efficiently?  Set the value of the `query_to_optimize` variable below to one of `1`, `2`, or `3`.  (Your answer should have type **integer**.)","metadata":{}},{"cell_type":"code","source":"# Fill in your answer\nquery_to_optimize = ____\n\n# Check your answer\nq_1.check()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\n#q_1.hint()\nq_1.solution()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2) Make it easier to find Mitzie! \n\nYou have the following two tables:\n\n![](https://i.imgur.com/E9jikOQ.png)\n\nThe `CostumeLocations` table shows timestamped GPS data for all of the pet costumes in the database, where `CostumeID` is a unique identifier for each costume.  \n\nThe `CostumeOwners` table shows who owns each costume, where the `OwnerID` column contains unique identifiers for each (human) owner.  Note that each owner can have more than one costume!  And, each costume can have more than one owner: this allows multiple individuals from the same household (all with their own, unique `OwnerID`) to access the locations of their pets' costumes.\n\nSay you need to use these tables to get the current location of one pet in particular: Mitzie the Dog recently ran off chasing a squirrel, but thankfully she was last seen in her hot dog costume!\n\nOne of Mitzie's owners (with owner ID `MitzieOwnerID`) logs into your website to pull the last locations of every costume in his possession.  Currently, you get this information by running the following query:\n\n```sql\nWITH LocationsAndOwners AS \n(\nSELECT * \nFROM CostumeOwners co INNER JOIN CostumeLocations cl\n   ON co.CostumeID = cl.CostumeID\n),\nLastSeen AS\n(\nSELECT CostumeID, MAX(Timestamp)\nFROM LocationsAndOwners\nGROUP BY CostumeID\n)\nSELECT lo.CostumeID, Location \nFROM LocationsAndOwners lo INNER JOIN LastSeen ls \n\tON lo.Timestamp = ls.Timestamp AND lo.CostumeID = ls.CostumeID\nWHERE OwnerID = MitzieOwnerID\n```\n\nIs there a way to make this faster or cheaper?","metadata":{}},{"cell_type":"code","source":"# Line below will give you a hint\nq_2.hint()","metadata":{"execution":{"iopub.status.busy":"2022-10-01T14:26:48.333043Z","iopub.execute_input":"2022-10-01T14:26:48.333464Z","iopub.status.idle":"2022-10-01T14:26:48.345142Z","shell.execute_reply.started":"2022-10-01T14:26:48.333434Z","shell.execute_reply":"2022-10-01T14:26:48.344455Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 4, \"questionId\": \"2_Mitzie\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Hint: Do you see any large merges in the query?","text/markdown":"<span style=\"color:#3366cc\">Hint:</span> Do you see any large merges in the query?"},"metadata":{}}]},{"cell_type":"code","source":"# View the solution (Run this code cell to receive credit!)\nq_2.solution()","metadata":{"execution":{"iopub.status.busy":"2022-10-01T14:27:24.330744Z","iopub.execute_input":"2022-10-01T14:27:24.331097Z","iopub.status.idle":"2022-10-01T14:27:24.340726Z","shell.execute_reply.started":"2022-10-01T14:27:24.331072Z","shell.execute_reply":"2022-10-01T14:27:24.339675Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"questionId\": \"2_Mitzie\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \nYes. Working with the LocationsAndOwners table is very inefficient, because it’s a big table. There are a few options here, and which works best depends on database specifics. One likely improvement is\n\n```\nWITH CurrentOwnersCostumes AS\n(\nSELECT CostumeID \nFROM CostumeOwners \nWHERE OwnerID = MitzieOwnerID\n),\nOwnersCostumesLocations AS\n(\nSELECT cc.CostumeID, Timestamp, Location \nFROM CurrentOwnersCostumes cc INNER JOIN CostumeLocations cl\n    ON cc.CostumeID = cl.CostumeID\n),\nLastSeen AS\n(\nSELECT CostumeID, MAX(Timestamp)\nFROM OwnersCostumesLocations\nGROUP BY CostumeID\n)\nSELECT ocl.CostumeID, Location \nFROM OwnersCostumesLocations ocl INNER JOIN LastSeen ls \n    ON ocl.timestamp = ls.timestamp AND ocl.CostumeID = ls.costumeID\n```\n\n**Why is this better?**\n\nInstead of doing large merges and running calculations (like finding the last timestamp) for every costume, we discard the rows for other owners as the first step. So each subsequent step (like calculating the last timestamp) is working with something like 99.999% fewer rows than what was needed in the original query.\n\nDatabases have something called “Query Planners” to optimize details of how a query executes even after you write it. Perhaps some query planner would figure out the ability to do this. But the original query as written would be very inefficient on large datasets.","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \nYes. Working with the LocationsAndOwners table is very inefficient, because it’s a big table. There are a few options here, and which works best depends on database specifics. One likely improvement is\n\n```\nWITH CurrentOwnersCostumes AS\n(\nSELECT CostumeID \nFROM CostumeOwners \nWHERE OwnerID = MitzieOwnerID\n),\nOwnersCostumesLocations AS\n(\nSELECT cc.CostumeID, Timestamp, Location \nFROM CurrentOwnersCostumes cc INNER JOIN CostumeLocations cl\n    ON cc.CostumeID = cl.CostumeID\n),\nLastSeen AS\n(\nSELECT CostumeID, MAX(Timestamp)\nFROM OwnersCostumesLocations\nGROUP BY CostumeID\n)\nSELECT ocl.CostumeID, Location \nFROM OwnersCostumesLocations ocl INNER JOIN LastSeen ls \n    ON ocl.timestamp = ls.timestamp AND ocl.CostumeID = ls.costumeID\n```\n\n**Why is this better?**\n\nInstead of doing large merges and running calculations (like finding the last timestamp) for every costume, we discard the rows for other owners as the first step. So each subsequent step (like calculating the last timestamp) is working with something like 99.999% fewer rows than what was needed in the original query.\n\nDatabases have something called “Query Planners” to optimize details of how a query executes even after you write it. Perhaps some query planner would figure out the ability to do this. But the original query as written would be very inefficient on large datasets.\n"},"metadata":{}}]},{"cell_type":"markdown","source":"# Conclusion\n\nCongratulations!  You have made it to the end of the micro-course.  You should be proud of all of your hard work!\n\nThere is still a lot of room to build knowledge and experience.  In particular, you're encouraged to look through our BigQuery **[datasets](https://kaggle.com/datasets)** to practice your new skills.","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/advanced-sql/discussion) to chat with other learners.*","metadata":{}}]}